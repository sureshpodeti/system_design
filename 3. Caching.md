# Caching
LB helps in horizontal scaling
Caching enables better use of resources already in use.

works on the **locality of reference** principle.

Used in almost every layer of computing: _Hardware_,_OS_, _Web browsers_, and _web applications_ and more.

## Properties of caching
1. Stored in **Short time** memory (eg. in-memory)
2. Limited amount of **space** 

So, it is faster and contains only the most recent items.

Mostly found nearest to _frontend_.

## Application server cache
Placing cache at the request layer itself.

Cache on the request layer could be on memory (very fast), or local disk (faster than going to network storage)

**Problem** <br>
If the request layer is
expanded to multiple nodes, itâ€™s still quite possible to have each node host its own
cache. However, if your load balancer randomly distributes requests across the
nodes, the same request will go to different nodes, thus increasing cache misses. Two
choices for **overcoming** this hurdle are **global caches** and **distributed caches**

## Content delivery network (CDN)
Its a kind of **cache**.<br>
Comes into play for sites serving **large amounts of static data**.<br>
The request will always ask CDN for a piece of static data.<br>
Serves content if the requested content is available. Otherwise queries backend servers for the content, caches it locally, and serve it to the requested user.<br>

## Cache invalidation 
Require to keep cache and source of truth (database) in sync.
If data is updated in DB, previous data should be invalidated in the cache.
If not can cause inconsistency

#### Schemes of cache invalidations
1. **Write-through cache** - Data is written in cache and in corresonding database at the same time. Complete consistency b/w cache and database
2. **Write-around cache** - Data is directly written to database bypassing cache. Reduces cache overflood. Read request for the most recently written data misses the cache.
3. **Write-back cache** - Data is only written to cache, and updated on frequent intervals with database. useful: low latency, and high throuhput for write-applications.
 However things can go wrong if the only cache crashes.
 
## Cache eviction
Some cache cleared for new objects to store. as space is limited, and stored for short time.

#### Cache eviction policies
1. **First-in-first-out (FIFO)** - Evicts first block regardless of how many times, how often it was accessed before.
2. **Last-in-first-out (LIFO)** - Evicts last block accessed 
3. **Least recently used (LRU)** - Evicts least recently used items first
4. **Most recently used (MRU)** - Discards most recently used items first
5. **Least frequently used (LFU)** - Counts how often a time is used, and removes least frequently used items first
6. **Random replacement (RR)** - Randomly selects a candidate and discards to make space whenever neccessary


